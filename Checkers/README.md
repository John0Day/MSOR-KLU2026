6Ã—6 Checkers â€” Reinforcement Learning vs Heuristic Strategy
This project implements a full 6Ã—6 Checkers environment designed for reinforcement learning experimentation, heuristic strategy comparison, and MDP modeling. It was developed as part of the MSOR KLU2026 (Management Science / Operations Research) coursework at KÃ¼hne Logistics University.
The project includes:
â€¢	A Tkinter GUI for human vs human play
â€¢	A Gymnasium environment for reinforcement learning
â€¢	A heuristic rule based agent
â€¢	A Q learning agent
â€¢	Training and evaluation scripts
â€¢	Visualizations of learning performance
â€¢	A complete MDP formulation of the game
________________________________________
Features
Complete 6Ã—6 Checkers Engine
â€¢	Forced captures
â€¢	Multi jump sequences
â€¢	Promotion to king
â€¢	Legal move generation
â€¢	Turn switching
â€¢	Deterministic transitions (supports MDP modeling)
Gymnasium Environment
Implements:
â€¢	reset()
â€¢	step()
â€¢	observation_space
â€¢	action_space
â€¢	Reproducible seeds
Heuristic Agent
A rule based strategy using a material evaluation function.
Q Learning Agent
â€¢	Tabular Q table
â€¢	Îµ greedy policy
â€¢	Reward shaping
â€¢	Training loop with visualization
Evaluation
â€¢	Q learning vs heuristic
â€¢	Win rate statistics
â€¢	Bar chart visualization
________________________________________
MDP Formulation
The 6Ã—6 Checkers game is modeled as a Markov Decision Process:
[ \mathcal{M} = (S, A, T, R, \gamma) ]
State Space (S)
[ S = {p_0, \ldots, p_{35}, m} ] Each square (p_i) âˆˆ {0,1,2,3,4}
m âˆˆ {1,2} indicates whose turn it is.
Action Space (A(s))
All legal moves, including forced captures and multi jump sequences.
Transition Function (T(s,a))
Deterministic: move piece â†’ remove captures â†’ promote â†’ continue multi jump â†’ switch turn.
Reward Function (R)
+1 win, âˆ’1 loss, 0 otherwise.
Discount Factor
Î³ = 0.99
________________________________________
Installation
Install required packages:
pip install gymnasium numpy matplotlib
(Optional) For all Gym extras:
pip install "gymnasium[all]"
________________________________________
How to Run the Project
1. Play the Game (Human vs Human GUI)
python gui_checkers.py
A Tkinter window will open.
________________________________________
2. Train the Q Learning Agent
python train_q_learning.py
This will:
â€¢	Train the agent for several thousand episodes
â€¢	Print progress
â€¢	Show a reward curve
________________________________________
3. Evaluate Q Learning vs Heuristic
python evaluate_agents.py
This will:
â€¢	Run 200 matches
â€¢	Print win/loss statistics
â€¢	Display a bar chart
________________________________________
Reinforcement Learning Setup
State Representation
â€¢	6Ã—6 board encoded as integers
â€¢	Player to move (0 = black, 1 = red)
Action Representation
â€¢	Index into the list of legal moves
â€¢	Maximum of ~40 moves per state
Reward Function
â€¢	+1 for win
â€¢	âˆ’1 for loss
â€¢	0 otherwise

Algorithm
â€¢	Tabular Q learning
â€¢	Îµ greedy exploration
â€¢	Î³ = 0.99
â€¢	Î± = 0.1
________________________________________
Example Results
After training, the Q learning agent consistently outperforms the heuristic baseline.
Agent	Wins (200 games)
Q learning	     200
Heuristic	      0
________________________________________
Educational Objectives (kept from the original project)
This project supports:
â€¢	Sequential decision modeling
â€¢	Reinforcement learning experimentation
â€¢	Heuristic strategy comparison
â€¢	MDP formulation and analysis
â€¢	Game environment simulation design
â€¢	Understanding the curse of dimensionality
â€¢	Practical implementation of RL algorithms
________________________________________
Course Context (kept from the original project)
This project was developed as part of:
MSOR KLU2026 â€” Management Science / Operations Research 
KÃ¼hne Logistics University
Focus areas:
â€¢	Optimization
â€¢	Decision modeling
â€¢	Reinforcement learning
â€¢	Computational solution methods
________________________________________
Contributors (kept from the original project)
â€¢	Isaac
â€¢	John
â€¢	Alhagie
â€¢	Chandar
â€¢	Satya
________________________________________
ðŸ“œ License
This project is for academic use.
________________________________________
AI Statement  
Parts of this project (structure, documentation, and code templates) were developed with assistance from Microsoft Copilot.
All implementation decisions, debugging, and analysis were carried out by the project team.

